{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import struct\n",
    "import os\n",
    "from matplotlib.pylab import plt\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./mnist_data/\"\n",
    "def read(dataset = \"training\", datatype='images'):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set. It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "        \n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "    if(datatype=='images'):\n",
    "        get_data = lambda idx: img[idx]\n",
    "    elif(datatype=='labels'):\n",
    "        get_data = lambda idx: lbl[idx]\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in range(len(lbl)):\n",
    "        yield get_data(i)\n",
    "        \n",
    "trainData=np.array(list(read('training','images')))\n",
    "trainLabels=np.array(list(read('training','labels')))\n",
    "testData=np.array(list(read('testing','images')))\n",
    "testLabels=np.array(list(read('testing','labels')))\n",
    "\n",
    "# Make data 2D\n",
    "trainData = trainData.reshape(trainData.shape[0], -1)\n",
    "testData = testData.reshape(testData.shape[0], -1)\n",
    "# Make labels 2D\n",
    "#trainLabels = trainLabels.reshape(trainLabels.shape[0], -1)\n",
    "#testLabels = testLabels.reshape(testLabels.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base and mixin classes for instance reduction techniques\n",
    "\n",
    "# Author: Dayvid Victor <dvro@cin.ufpe.br>\n",
    "# License: BSD Style\n",
    "import warnings\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors.classification import KNeighborsClassifier\n",
    "\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.externals import six\n",
    "\n",
    "\n",
    "class InstanceReductionWarning(UserWarning):\n",
    "    pass\n",
    "\n",
    "# Make sure that NeighborsWarning are displayed more than once\n",
    "warnings.simplefilter(\"always\", InstanceReductionWarning)\n",
    "\n",
    "\n",
    "class InstanceReductionBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n",
    "\n",
    "    \"\"\"Base class for instance reduction estimators.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class InstanceReductionMixin(InstanceReductionBase, ClassifierMixin):\n",
    "\n",
    "    \"\"\"Mixin class for all instance reduction techniques\"\"\"\n",
    "\n",
    "\n",
    "    def set_classifier(self):\n",
    "        \"\"\"Sets the classified to be used in the instance reduction process\n",
    "            and classification.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        classifier : classifier, following the KNeighborsClassifier style\n",
    "            (default = KNN)\n",
    "\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Labels for X.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        P : array-like, shape = [indeterminated, n_features]\n",
    "            Resulting training set.\n",
    "\n",
    "        q : array-like, shape = [indertaminated]\n",
    "            Labels for P\n",
    "        \"\"\"\n",
    "\n",
    "        self.classifier = classifier\n",
    "\n",
    "\n",
    "    def reduce_data(self, X, y):\n",
    "        \"\"\"Perform the instance reduction procedure on the given training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            Training set.0\n",
    "\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Labels for X.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_ : array-like, shape = [indeterminated, n_features]\n",
    "            Resulting training set.\n",
    "\n",
    "        y_ : array-like, shape = [indertaminated]\n",
    "            Labels for X_\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y, reduce_data=True):\n",
    "        \"\"\"\n",
    "        Fit the InstanceReduction model according to the given training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vector, where n_samples in the number of samples and\n",
    "            n_features is the number of features.\n",
    "            Note that centroid shrinking cannot be used with sparse matrices.\n",
    "        y : array, shape = [n_samples]\n",
    "            Target values (integers)\n",
    "        reduce_data : bool, flag indicating if the reduction would be performed\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        if reduce_data:\n",
    "            self.reduce_data(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, n_neighbors=1):\n",
    "        \"\"\"Perform classification on an array of test vectors X.\n",
    "\n",
    "        The predicted class C for each sample in X is returned.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        C : array, shape = [n_samples]\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        The default prediction is using KNeighborsClassifier, if the\n",
    "        instance reducition algorithm is to be performed with another\n",
    "        classifier, it should be explicited overwritten and explained\n",
    "        in the documentation.\n",
    "        \"\"\"\n",
    "        X = check_array(X)\n",
    "        if not hasattr(self, \"X_\") or self.X_ is None:\n",
    "            raise AttributeError(\"Model has not been trained yet.\")\n",
    "\n",
    "        if not hasattr(self, \"y_\") or self.y_ is None:\n",
    "            raise AttributeError(\"Model has not been trained yet.\")\n",
    "\n",
    "        if self.classifier == None:\n",
    "            self.classifier = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "        self.classifier.fit(self.X_, self.y_)\n",
    "        return self.classifier.predict(X)\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Return probability estimates for the test data X.\n",
    "        after a given prototype selection algorithm.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape = (n_samples, n_features)\n",
    "            A 2-D array representing the test points.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
    "        of such arrays if n_outputs > 1.\n",
    "        The class probabilities of the input samples. Classes are ordered\n",
    "        by lexicographic order.\n",
    "        \"\"\"\n",
    "        self.classifier.fit(self.X_, self.y_)\n",
    "        return self.classifier.predict_proba(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Condensed-Nearest Neighbors\n",
    "\"\"\"\n",
    "\n",
    "# Author: Dayvid Victor <victor.dvro@gmail.com>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from sklearn.neighbors.classification import KNeighborsClassifier\n",
    "\n",
    "#from base import InstanceReductionMixin\n",
    "\n",
    "\n",
    "class CNN(InstanceReductionMixin):\n",
    "    \"\"\"Condensed Nearest Neighbors.\n",
    "\n",
    "    Each class is represented by a set of prototypes, with test samples\n",
    "    classified to the class with the nearest prototype.\n",
    "    The Condensed Nearest Neighbors removes the redundant instances,\n",
    "    maintaining the samples in the decision boundaries.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_neighbors : int, optional (default = 1)\n",
    "        Number of neighbors to use by default for :meth:`k_neighbors` queries.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    `prototypes_` : array-like, shape = [indeterminated, n_features]\n",
    "        Selected prototypes.\n",
    "\n",
    "    `labels_` : array-like, shape = [indeterminated]\n",
    "        Labels of the selected prototypes.\n",
    "\n",
    "    `reduction_` : float, percentual of reduction.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from protopy.selection.cnn import CNN\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "    >>> y = np.array([1, 1, 1, 2, 2, 2])\n",
    "    >>> cnn = CNN()\n",
    "    >>> cnn.fit(X, y)\n",
    "    CNN(n_neighbors=1)\n",
    "    >>> print(cnn.predict([[-0.8, -1]]))\n",
    "    [1]\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    sklearn.neighbors.KNeighborsClassifier: nearest neighbors classifier\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The Condensed Nearest Neighbor is one the first prototype selection\n",
    "    technique in literature.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    P. E. Hart, The condensed nearest neighbor rule, IEEE Transactions on\n",
    "    Information Theory 14 (1968) 515–516.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=1, M=None):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.classifier = None\n",
    "        self.M = M\n",
    "\n",
    "    def reduce_data(self, X, y):\n",
    "\n",
    "        X, y = check_X_y(X, y, accept_sparse=\"csr\")\n",
    "\n",
    "        if self.classifier == None:\n",
    "            self.classifier = KNeighborsClassifier(n_neighbors=self.n_neighbors)\n",
    "\n",
    "        prots_s = []\n",
    "        labels_s = []\n",
    "\n",
    "        classes = np.unique(y)\n",
    "        self.classes_ = classes\n",
    "\n",
    "        # Adding one sample from each class\n",
    "        for cur_class in classes:\n",
    "            mask = y == cur_class\n",
    "            insts = X[mask]\n",
    "            prots_s = prots_s + [insts[np.random.randint(0, insts.shape[0])]]\n",
    "            labels_s = labels_s + [cur_class]\n",
    "\n",
    "        self.classifier.fit(np.asarray(prots_s), np.asarray(labels_s))\n",
    "        \n",
    "        for sample, label in zip(X, y):\n",
    "            if self.M is not None and len(prots_s) == self.M:\n",
    "                break\n",
    "            if self.classifier.predict(sample.reshape(1, -1)) != [label]:\n",
    "                prots_s = prots_s + [sample]\n",
    "                labels_s = labels_s + [label]\n",
    "                #assert(len(prots_s) == len(labels_s))\n",
    "                self.classifier.fit(prots_s, labels_s)\n",
    "        \n",
    "\n",
    "        if self.M is not None and len(prots_s) < self.M:\n",
    "            to_add = self.M - len(prots_s)\n",
    "            idx = np.random.randint(0, X.shape[0], size=to_add)\n",
    "            prots_s =  np.concatenate((np.asarray(prots_s), X[idx]), axis=0)\n",
    "            labels_s = np.concatenate((np.asarray(labels_s), y[idx]), axis=0)\n",
    "            self.classifier.fit(prots_s, labels_s)\n",
    "            \n",
    "        self.X_ = np.asarray(prots_s)\n",
    "        self.y_ = np.asarray(labels_s)\n",
    "        self.reduction_ = 1.0 - float(len(self.y_))/len(y)\n",
    "        return self.X_, self.y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples:60000\n"
     ]
    }
   ],
   "source": [
    "print(\"number of samples:{}\".format(trainData.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples:43604\n"
     ]
    }
   ],
   "source": [
    "# Imbalance the dataset\n",
    "classes = np.unique(trainLabels)\n",
    "b = np.random.uniform(0.30,0.7, 5)\n",
    "# print(a)\n",
    "sample_subsets = []\n",
    "target_subsets = []\n",
    "for cur_class in range(5):\n",
    "    mask = trainLabels == cur_class\n",
    "    insts = trainData[mask]\n",
    "    a = np.random.randint(0, insts.shape[0], (int)(insts.shape[0]*(b[cur_class])))\n",
    "    sample_subsets.append(insts[a])\n",
    "    target_subsets.append(trainLabels[mask][a])\n",
    "\n",
    "for cur_class in range(5, 10):\n",
    "    mask = trainLabels == cur_class\n",
    "    insts = trainData[mask]\n",
    "    sample_subsets.append(insts)\n",
    "    target_subsets.append(trainLabels[mask])\n",
    "    \n",
    "# permutations\n",
    "X_ = np.asarray(sample_subsets)\n",
    "y_ = np.asarray(target_subsets)\n",
    "X = X_[0]\n",
    "y = [0] * len(X_[0])\n",
    "for i in range(1, 10):\n",
    "    X = np.concatenate((X, X_[i]), axis=0)\n",
    "    y += [i] * len(X_[i])\n",
    "    \n",
    "y = np.asarray(y)\n",
    "\n",
    "for _ in range(10):\n",
    "    a = np.random.permutation(X.shape[0])\n",
    "    X = X[a]\n",
    "    y = y[a]\n",
    "    \n",
    "trainData = X\n",
    "trainLabels = y\n",
    "print(\"number of samples:{}\".format(trainData.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples reduced to:(4968, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9312"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_new = CNN(n_neighbors=1)\n",
    "cnn_new.fit(trainData, trainLabels)\n",
    "print(\"Number of samples reduced to:{}\".format(cnn_new.X_.shape))\n",
    "cnn_new.score(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_random_samples(X, y, M):\n",
    "    \n",
    "    #indexes = np.random.randint(0, X.shape[0], size=M, seed=42)\n",
    "    indexes = np.random.choice(X.shape[0], size=M, replace=False)\n",
    "    prots_s = X[indexes]\n",
    "    labels_s = y[indexes]\n",
    "        \n",
    "    return np.asarray(prots_s).reshape(-1, 784), np.asarray(labels_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prototype samples:3813\n",
      "Average accuracy:0.9229\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for _ in range(1):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "    ProtoData, ProtoLabels = choose_random_samples(trainData, trainLabels, 3813)\n",
    "    neigh.fit(ProtoData, ProtoLabels) \n",
    "    acc.append(neigh.score(testData, testLabels))\n",
    "\n",
    "print(\"Number of prototype samples:{}\".format(ProtoData.shape[0]))\n",
    "print(\"Average accuracy:{}\".format(sum(acc)/len(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples reduced to:(100, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7405"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_new = CNN(n_neighbors=1, M=100)\n",
    "cnn_new.fit(trainData, trainLabels)\n",
    "print(\"Number of samples reduced to:{}\".format(cnn_new.X_.shape))\n",
    "cnn_new.score(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples reduced to:(500, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8513"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_new = CNN(n_neighbors=1, M=500)\n",
    "cnn_new.fit(trainData, trainLabels)\n",
    "print(\"Number of samples reduced to:{}\".format(cnn_new.X_.shape))\n",
    "cnn_new.score(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples reduced to:(1000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8888"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_new = CNN(n_neighbors=1, M=1000)\n",
    "cnn_new.fit(trainData, trainLabels)\n",
    "print(\"Number of samples reduced to:{}\".format(cnn_new.X_.shape))\n",
    "cnn_new.score(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples reduced to:(5000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9302"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_new = CNN(n_neighbors=1, M=5000)\n",
    "cnn_new.fit(trainData, trainLabels)\n",
    "print(\"Number of samples reduced to:{}\".format(cnn_new.X_.shape))\n",
    "cnn_new.score(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples reduced to:(10000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9484"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_new = CNN(n_neighbors=1, M=10000)\n",
    "cnn_new.fit(trainData, trainLabels)\n",
    "print(\"Number of samples reduced to:{}\".format(cnn_new.X_.shape))\n",
    "cnn_new.score(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
